# AI Art vs Human Art Classification

[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/release/python-3106/)

> A deep learning project to classify and distinguish AI-generated artwork from human-created artwork.

---

## ğŸ‘¥ Team Members

| Name | GitHub | Role |
|------|--------|------|
| Gechen Ma | [@Gechen989898](https://github.com/Gechen989898) | Team Lead / ML Engineer |
| Didier Peran Ganthier | [@didierganthier](https://github.com/didierganthier) | ML Engineer |
| Alexis Kipiani | [@Alex-gitacc](https://github.com/Alex-gitacc) | Data Engineer |
| Mame | [@kharitsama](https://github.com/kharitsama) | ML Engineer |

---

## ğŸ“‹ Project Overview

With the rise of AI image generation tools (DALL-E, Midjourney, Stable Diffusion), distinguishing between AI-generated and human-created art has become increasingly challenging. This project aims to build a robust classification model that can accurately identify the origin of artwork.

### Objectives
- Build and compare multiple deep learning architectures
- Achieve high accuracy in classifying AI vs Human art
- Deploy a functional API for real-time predictions
- Create an interactive demo interface

---

## ğŸ“Š Dataset

**Tiny GenImage** - A lightweight version of the GenImage dataset, perfect for training models on modern diffusion-generated images.

| Dataset | Description | Link |
|---------|-------------|------|
| **Tiny GenImage** | Compact dataset featuring AI-generated images from modern diffusion models (Stable Diffusion, Midjourney, etc.) vs real images | [Kaggle](https://www.kaggle.com/datasets/yangsangtai/tiny-genimage) |

---

## ğŸ—ï¸ Project Architecture

```
AI_Art_vs_Human_Art/
â”œâ”€â”€ README.md
â”œâ”€â”€ Makefile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ .env.sample
â”œâ”€â”€ .gitignore
â”œâ”€â”€ raw_data/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â””â”€â”€ human/
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ ai/
â”‚       â””â”€â”€ human/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â””â”€â”€ 04_evaluation.ipynb
â”œâ”€â”€ ai_art_classifier/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cnn_baseline.py
â”‚   â”‚   â”œâ”€â”€ resnet.py
â”‚   â”‚   â”œâ”€â”€ efficientnet.py
â”‚   â”‚   â””â”€â”€ vision_transformer.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â””â”€â”€ callbacks.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ fast_api.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ (saved model weights)
â””â”€â”€ tests/
    â””â”€â”€ (unit tests)
```

---

## ğŸ§  Models to Implement

1. **CNN Baseline** - Custom Convolutional Neural Network
2. **ResNet50** - Transfer Learning with ResNet
3. **EfficientNetB0** - Transfer Learning with EfficientNet
4. **Vision Transformer (ViT)** - Transformer-based approach

---

## ğŸ“… Project Timeline (6 Weeks)

### Week 1: Project Setup & Data Collection
| Task | Assignee | Status |
|------|----------|--------|
| Set up GitHub repository & branch protection | Gechen | â¬œ |
| Create project structure & Makefile | Didier | â¬œ |
| Download and organize Tiny GenImage dataset | Alexis | â¬œ |
| Set up virtual environment & requirements.txt | Didier | â¬œ |
| Create Trello board with all tasks | Mame | â¬œ |

### Week 2: Data Exploration & Preprocessing
| Task | Assignee | Status |
|------|----------|--------|
| Exploratory Data Analysis (EDA) notebook | Alexis | â¬œ |
| Data visualization (class distribution, samples) | Alexis | â¬œ |
| Implement data augmentation pipeline | Gechen | â¬œ |
| Create data loader classes | Didier | â¬œ |
| Implement train/val/test split logic | Mame | â¬œ |
| Document data preprocessing steps | All | â¬œ |

### Week 3: Baseline Model Development
| Task | Assignee | Status |
|------|----------|--------|
| Implement CNN baseline model | Gechen | â¬œ |
| Implement ResNet transfer learning | Didier | â¬œ |
| Create training pipeline with callbacks | Mame | â¬œ |
| Set up experiment tracking (MLflow/W&B) | Alexis | â¬œ |
| Train and evaluate CNN baseline | Gechen | â¬œ |
| Train and evaluate ResNet model | Didier | â¬œ |

### Week 4: Advanced Models & Optimization
| Task | Assignee | Status |
|------|----------|--------|
| Implement EfficientNet model | Mame | â¬œ |
| Implement Vision Transformer (ViT) | Alexis | â¬œ |
| Hyperparameter tuning for best models | Gechen | â¬œ |
| Cross-validation implementation | Didier | â¬œ |
| Model comparison analysis | All | â¬œ |
| Implement ensemble method (optional) | Gechen | â¬œ |

### Week 5: API Development & Deployment
| Task | Assignee | Status |
|------|----------|--------|
| Build FastAPI prediction endpoint | Didier | â¬œ |
| Create Docker container | Gechen | â¬œ |
| Implement image upload functionality | Mame | â¬œ |
| Deploy API to cloud (GCP/AWS) | Alexis | â¬œ |
| Write API documentation | Didier | â¬œ |
| Load testing & optimization | Gechen | â¬œ |

### Week 6: Demo, Testing & Presentation
| Task | Assignee | Status |
|------|----------|--------|
| Build Streamlit/Gradio demo interface | Mame | â¬œ |
| Write unit tests | Alexis | â¬œ |
| Final model evaluation on test set | Gechen | â¬œ |
| Prepare presentation slides | All | â¬œ |
| Record demo video | Didier | â¬œ |
| Final code review & documentation | All | â¬œ |

---

## ğŸš€ Getting Started

### Prerequisites
- Python 3.10.6
- pyenv (recommended)

### Installation

```bash
# Clone the repository
git clone git@github.com:Gechen989898/AI_Art_vs_Human_Art.git
cd AI_Art_vs_Human_Art

# Create and activate virtual environment
pyenv virtualenv 3.10.6 AI_Art_vs_Human_Art
pyenv activate AI_Art_vs_Human_Art

# Install dependencies
pip install -r requirements.txt
```

### Download Data

```bash
# Using Kaggle CLI
kaggle datasets download -d yangsangtai/tiny-genimage
unzip tiny-genimage.zip -d raw_data/
```

### Training

```bash
# Train baseline CNN
make train_cnn

# Train ResNet
make train_resnet

# Train all models
make train_all
```

### Running the API

```bash
# Start FastAPI server
make run_api
```

---

## ğŸ“ˆ Expected Results

| Model | Target Accuracy | Training Time |
|-------|-----------------|---------------|
| CNN Baseline | ~85% | ~30 min |
| ResNet50 | ~92% | ~1 hour |
| EfficientNetB0 | ~94% | ~1 hour |
| ViT | ~95% | ~2 hours |

---

## ğŸ› ï¸ Tech Stack

- **Deep Learning**: TensorFlow / PyTorch
- **Data Processing**: NumPy, Pandas, OpenCV
- **Visualization**: Matplotlib, Seaborn
- **API**: FastAPI
- **Deployment**: Docker, GCP/AWS
- **Demo**: Streamlit / Gradio
- **Experiment Tracking**: MLflow / Weights & Biases

---

## ğŸ“š Resources

- [CIFAKE Paper](https://arxiv.org/abs/2303.14126)
- [Vision Transformer Paper](https://arxiv.org/abs/2010.11929)
- [EfficientNet Paper](https://arxiv.org/abs/1905.11946)
- [Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)

---

## ğŸ“ License

This project is for educational purposes.

---

## ğŸ¤ Contributing

1. Create a feature branch from `master`
2. Make your changes
3. Submit a Pull Request
4. Request review from at least one team member

**Branch naming convention**: `feature/<your-name>/<feature-description>`

---

*Project started: February 2026*
